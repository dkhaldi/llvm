# Intel-specific matrix features

:source-highlighter: coderay
:coderay-linenums-mode: table
:dpcpp: pass:[DPC++]

// This section needs to be after the document title.
:doctype: book
:toc2:
:toc: left
:encoding: utf-8
:lang: en

:blank: pass:[ +]

// Set the default source code type in this document to C++,
// for syntax highlighting purposes.  This is needed because
// docbook uses c++ and html5 uses cpp.
:language: {basebackend@docbook:c++:cpp}


== Notice

Copyright (c) 2021-2022 Intel Corporation.  All rights reserved.

NOTE: Khronos(R) is a registered trademark and SYCL(TM) and SPIR(TM) are
trademarks of The Khronos Group Inc.  OpenCL(TM) is a trademark of Apple Inc.
used by permission by Khronos.

This extension is written against the SYCL 2020 revision 5 specification.  All
references below to the "core SYCL specification" or to section numbers in the
SYCL specification refer to that revision.

**_NOTE:_** This document describes the extra features and details for the implementation of `joint_matrix` extension on Intel AMX and Intel XMX.
 This is an initial experimental version to try out functionality
and performance, and **future versions of this API may change in ways that are incompatible with this experimental version**.

## Introduction
The Intel backend implementations on both Intel AMX and Intel XMX  support `joint_matrix`, `joint_matrix_load`, `joint_matrix_store`, `joint_matrix_mad`, `joint_matrix_fill`, `get_wi_data`, and the query interface, as they are defined in the sycl_ext_oneapi_matrix extension. There are additional specifics about the supported layouts that enable extra performance and functionality listed in this document.
This extension presents some supplementary Intel AMX and Intel XMX features not contained within the sycl_ext_oneapi_matrix extension. The additional features are built on top of the sycl_ext_oneapi_matrix extension but are only supported by the Intel AMX and Intel XMX backends.

## Feature test macro

This extension provides a feature-test macro as described in the core SYCL
specification section 6.3.3 "Feature test macros".  Therefore, an
implementation supporting this extension must predefine the macro
`SYCL_EXT_INTEL_MATRIX` to one of the values defined in the table below.
Applications can test for the existence of this macro to determine if the
implementation supports this feature, or applications can test the macro's
value to determine which of the extension's APIs the implementation supports.

[frame="none",options="header"]
|======================
|Value |Description
|1     |Introduce `packed` layout and extend `joint_matrix_store` to Matrix A and B.
|======================


## Extra Functionality

### Layout
Besides row major and column major layouts, `layout` introduces the custom layout packed layout that refers to the VNNI format descibed in the following section.

```c++
namespace sycl::ext::intel::experimental::matrix {
enum class layout {
  packed
};
}
```


### Layout argument in `joint_matrix_load`
`layout` in `joint_matrix_load` can take `packed` as argument to specify that the data has already been transformed into VNNI format (`packed`). in this case, `stride` argument of `joint_matrix_load` describes the number of elements between consecutive rows for packed layouts.

In order to get maximum performance on Intel AMX and Intel XMX, prepacking data in the memory is necessary. If users did not specify the packed layouts, transforms done by the implementation will be slow due to extra scatter/gather operations. Hence, we expose the `packed` layout to the user to specify that A or B have already been VNNIed. The packed or VNNI layout is introduced in the `VNNI layout` section below.

IMPORTANT: In the current Intel AMX and Intel XMX implementations, the layout in the load of matrix B (provided by the `layout memL` parameter below) must be `packed` or `row_major`. Automatic VNNI transform is supported on AMX. The layout in the load of matrices A and C must be `row_major`, and the layout in the store of matrix C (provided by the `layout memL` parameter below) must also be `row_major`.

### Store Operation
Besides store of matrix `accumulator`, the Intel implementation allows store on matrix `a` and `b` as well. 

#### Store
```c++
namespace sycl::ext::intel::experimental::matrix {
  template <typename Group, typename T, size_t NumRows, size_t NumCols,
            use Use, layout Layout, access::address_space Space>
  void joint_matrix_store(Group sg,
    joint_matrix<Group, T, Use, NumRows, NumCols, Layout> &res,
    multi_ptr<T, Space, IsDecorated> src, size_t stride);
}
```


## VNNI/Packed Layout
Intel AMX and Intel XMX compute assumes that the B tile register (src1) is in the VNNI format as they need 32bit of K-data in A and B to be contiguous in memory. 
The VNNI blocking factor is 2 in the case of 16-bit types, and it is 4 in the case of 8-bit types. While the current implementation assumes that the matrix has been already packed by the user for performance reasons, the layout information is needed to inform the implementation about this transformation.  The following example illustrates how a matrix in `row_major` layout is transformed into the `packed` layout for a 16-bit type.

#### Example 1: 16-bit elements
      // Example of a 4 row x 4 column matrix using a 16-bit data element, in row-major layout.
      // Element a1 is contiguous in memory with element b1, etc.
      // ---------------------------------
      // a1, b1, c1, d1
      // a2, b2, c2, d2
      // a3, b3, c3, d3
      // a4, b4, c4, d4
      // ---------------------------------
      // The same matrix reformatted in packed layout. 
      // Here, packing of 2 elements is needed to form 32 bits.
      // Element a1 is contiguous in memory with element a2, etc.
      // ---------------------------------
      // a1, a2, b1, b2, c1, c2, d1, d2
      // a3, a4, b3, b4, c3, c4, d3, d4

#### Example 2: 8-bit elements

      // Example of a 4 row x 4 column matrix using a 8-bit data element, in row-major layout.
      // Element a1 is contiguous in memory with element b1, etc.
      // ---------------------------------
      // a1, b1, c1, d1
      // a2, b2, c2, d2
      // a3, b3, c3, d3
      // a4, b4, c4, d4
      // ---------------------------------
      // The same matrix reformatted in packed layout.  
      // Here, packing of 4 elements is needed to form 32 bits.
      // Elements a1, a2, a3, a4 are contiguous in memory, etc.
      // ---------------------------------
      // a1, a2, a3, a4, b1, b2, b3, b4, c1, c2, c3, c4, d1, d2, d3, d4

## Supported Combinations Per Hardware

The table below provides a list of the combinations that `joint_matrix` implementations support on each of Intel AMX and Intel XMX hardware. Note that these can be returned in a parametrized way using the `tpu_params` query class.

### Intel AMX Supported Combinations

[frame="none",options="header"]
|======================
| A type | B type | Accumulator type | M | N | K
| (u)int8_t  | (u)int8_t |  int32_t  |  +<=+ 16 |  +<=+ 16 |  +<=+ 64
|  bf16       |  bf16   |   fp32   |  +<=+ 16 |  +<=+ 16   |  +<=+ 32
|======================

### Intel XMX Supported Combinations

[frame="none",options="header"]
|======================
| A type | B type | Accumulator type | M | N | K
| (u)int8_t  | (u)int8_t |  int32_t  |  +<=+ 8 |  16 |  32
|  fp16       |  fp16   |   fp32   |  +<=+ 8 |  16   |  16
|  bf16       |  bf16   |   fp32   |  +<=+ 8 |  16   |  16
|======================


## WI data to joint matrix mapping coordinates information for piece-wise operations
The indexing provided inside the `wi_data` class accesses only the portion of the matrix held by the current WI. It is not possible to know the location of this portion in the joint matrix because the coordinates mapping  is implementation defined and changes from one backend to the other. For general piece-wise operations like sum of rows of a matrix, the WI data to joint matrix mapping information is needed to reason about the matrix view.
The joint matrix extension aims to enable writing, as much as possible, one code to run on different backends. If backend X states that a WI owns one exact column of the matrix for instance, writing the following code will work only on that backend for that version of hardware. If a different implementation is used, the same WI may own only half of the row if, for example, the SG size increased.
The following code locally calculates sum of rows of matrix `joint_matrix<sub_group, int8_t, use::a, 8, 16, layout::row_major> tA;`. In this example, we assume each WI owns 2 successive columns of `tA` and the sub-group size is 8. `data.length` returns 16 elements per WI.

[frame="none"]
|======================
| a00 | a01 | a02 |a03 | a04 | a05|a06|a07|a08|a09|a010|a011|a012|a013|a014|a015
| a10 | a11 | a12 |a13 | a14 | a15|a16|a17|a18|a19|a110|a111|a112|a113|a114|a115
| a20 | a21 | a22 |a23 | a24 | a25|a26|a27|a28|a29|a210|a211|a212|a213|a214|a215
| a30 | a31 | a32 |a33 | a34 | a35|a36|a37|a38|a39|a310|a311|a312|a313|a314|a315
| a40 | a41 | a42 |a43 | a44 | a45|a46|a47|a48|a49|a410|a411|a412|a413|a414|a415
| a50 | a51 | a52 |a53 | a54 | a55|a56|a57|a58|a59|a510|a511|a512|a513|a514|a515
| a60 | a61 | a62 |a63 | a64 | a65|a66|a67|a68|a69|a610|a611|a612|a613|a614|a615
| a70 | a71 | a72 |a73 | a74 | a75|a76|a77|a78|a79|a710|a711|a712|a713|a714|a715
|======================

WI0 elements returned in `data`  are the first 2 columns as follows:

[frame="none"]
|======================
| a00 | a01 | a10 |a11 | a20 | a21|a30|a31|a40|a41|a50|a51|a60|a61|a70|a71
|======================

```c++
auto data = get_wi_data(sg, tA);
// each WI calculates local sum of rows
for (int row = 0; row < 8; row++) { 
  for (int i = 0; i < data.length()/8; ++i) {//WI owns 2 element per row
    sum_of_local_rows[row] += data[i+row*2];
  }
}  
```

The code above assumes knowledge of the distribution of the joint matrix across the different work-items. This is different when a different distribution happens.

For instance, if we assume a round-robin distribution of the joint matrix elements among the work-items, WI0 elements returned in `data`  are the first and 8th columns as follows:

[frame="none"]
|======================
| a00 | a10 | a20 |a30 | a40 | a50|a60|a70|a08|a18|a28|a38|a48|a58|a68|a78
|======================

The code becomes:

```c++
auto data = get_wi_data(sg, tA);
// each WI calculates local sum of rows
for (int row = 0; row < 8; row++) { 
  for (int i = 0; i < data.length()/8; ++i) {//WI owns 2 element per row
    sum_of_local_rows[row] += data[i*8+row];
  }
}  
```

In order to make element-wise operations on joint matrices agnostic to this distribution, instead of hard-coding this mapping, we use general backend and target-agnostic functionality. To this end, a new method is added to 'wi_element' to query this mapping.

```c++
namespace sycl::ext::intel::experimental::matrix {
 std::tuple<uint32_t, uint32_t> get_coord();
}
```

`get_coord` returns [row,col] coordinates of the current object `wi_element` of the joint matrix.  The code above results into the following:

```c++
auto data = get_wi_data(sg, tA);
// each WI calculates local sum of rows
for (int i = 0; i < data.length(); ++i) {
  auto [row, col] = data[i].get_coord();
  sum_of_local_rows[row] += data[i];
}  
```

## Open Questions
- Should the same class, `joint_matrix`, handle both cases where sizes are constant (GPU case) and when sizes are variable (CPU case)? Note that a Intel AMX 2d tile register permits sizes up to 1024 (16rowsx64cols) bytes that can be variable. The ability to define only one interface for both would make it possible to give the user a way to make use of the flexibility introduced by the CPU but at the same time save resources on the GPU. In a previous version of the design, we used `sycl::dynamic_extent`  to differentiate between static and dynamic sizes. But since this was not implemented at all, we decided to remove it. We can revisit this design choice if this comes up as part of a customer request or if SPIRV matrix extension extends its support to dynamic sizes.

## Revision History

[frame="none",options="header"]
|======================
|Rev |Date       |Author     |Changes
|1   |2022-11-07 |Dounia Khaldi |Add Intel-specific store API and layout information.
|2   |2023-01-09 |Dounia Khaldi |Add `get_coord` API.
|======================
