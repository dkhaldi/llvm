= sycl_ext_oneapi_matrix

:source-highlighter: coderay
:coderay-linenums-mode: table

// This section needs to be after the document title.
:doctype: book
:toc2:
:toc: left
:encoding: utf-8
:lang: en
:dpcpp: pass:[DPC++]

// Set the default source code type in this document to C++,
// for syntax highlighting purposes.  This is needed because
// docbook uses c++ and html5 uses cpp.
:language: {basebackend@docbook:c++:cpp}


== Notice

[%hardbreaks]
Copyright (c) 2021-2023 Intel Corporation.  All rights reserved.

Khronos(R) is a registered trademark and SYCL(TM) and SPIR(TM) are trademarks
of The Khronos Group Inc.  OpenCL(TM) is a trademark of Apple Inc. used by
permission by Khronos.

== Contact

To report problems with this extension, please open a new issue at:

https://github.com/intel/llvm/issues

== Dependencies

This extension is written against the SYCL 2020 revision 6 specification.  All
references below to the "core SYCL specification" or to section numbers in the
SYCL specification refer to that revision.

== Status
This is an experimental extension specification, intended to provide early
access to features and gather community feedback.  Interfaces defined in this
specification are implemented in {dpcpp}, but they are not finalized and may
change incompatibly in future versions of {dpcpp} without prior notice.
*Shipping software products should not rely on APIs defined in this
specification.*

== Backend support status
This extension is currently implemented in {dpcpp} only for devices
that contain a matrix hardware, specifically Intel(R) Advanced Matrix
Extensions (Intel(R) AMX), Intel(R) Xe Matrix Extensions (Intel(R)
XMX) and Nvidia(R) Tensor Cores.

The `joint_matrix_mad` function is an optional kernel feature as defined
in section 5.7 of the core SYCL specification.  Each device supports
only certain values for the `M`, `N`, and `K` template parameters and
only certain types for the `Ta`, `Tb`, and `Tc` template parameters.
Applications can use the query API in `matrix_params` or
`get_info<experimental::info::device::matrix>` to determine the set of
legal parameters for each device.  If the application submits a kernel using
an unsupported `joint_matrix_mad` combination, the implementation throws a
synchronous exception with the `errc::kernel_not_supported` error code
as described in section 5.7.

== Overview
Joint matrix is a SYCL extension for matrix hardware programming. It
unifies targets like Intel AMX in CPUs, Intel XMX in Intel GPUs and
Nvidia Tensor Cores. This provides a portable and performant API for
users who want to build their own neural networks applications,
perform custom optimzations, or experiment with new operations in a
timely and performing manner.

== Specification

=== Feature test macro

This extension provides a feature-test macro as described in the core SYCL
specification. An implementation supporting this extension must predefine
the macro `SYCL_EXT_ONEAPI_MATRIX` to one of the values defined in the
table below. Applications can test for the existence of this macro to
determine if the implementation supports this feature, or applications
can test the macro's value to determine which of the extension's
features the implementation supports.

[%header,cols="1,5"]
|===
|Value
|Description

|1
|The APIs of this experimental extension are not versioned, so the
 feature-test macro always has this value.
|===

=== New `joint_matrix` class
We introduce a new class called `joint_matrix`. The user needs to
specify the group memory scope, the type of the elements, the shape,
the matrix use, and the memory layout of the matrix. This results in
the following description:

```c++
namespace sycl::ext::oneapi::experimental::matrix {

template <typename Group, typename T, use Use, size_t Rows, size_t Cols,
          layout Layout = (Use == use::accumulator) ?
          layout::dynamic : /*unspecified*/ >
struct joint_matrix;

} // namespace sycl::ext::oneapi::experimental::matrix
```
When the `Use` parameter is `use::accumulator`, the `Layout` parameter
defaults to `layout::dynamic`, and it is invalid to specify any other
value for `Layout`. When `Use` has any other value, there is no default
for `Layout`, and the application must specify one explicitly.

==== Use
The main operation performed by the matrix hardware is `D=C+A*B`. `Use`
argument specifies the usage of the matrix: matrix left (`A`), matrix
right (`B`) or accumulator (`C`) and `D`. This is required by backend
implementations to reason about the layout of the matrix in registers.

```c++
namespace sycl::ext::oneapi::experimental::matrix {

enum class use {
  a,
  b,
  accumulator
};

} // namespace sycl::ext::oneapi::experimental::matrix
```

==== Shape
The shape of a `joint_matrix` refers to its number of rows `Rows` and
number of columns `Cols`.

==== Layout
This specifies the memory layout and it can be row major or column
major. `dynamic` layout is used on the `joint_matrix` type when this
is specified on the memory operations instead for the `accumulator`
matrix.

```c++
namespace sycl::ext::oneapi::experimental::matrix {

enum class layout {
  row_major,
  col_major,
  dynamic
}; // namespace sycl::ext::oneapi::experimental::matrix

}
```

==== Group Memory Scope
In this API, we use the terminology of `joint_matrix` instead of plain
`matrix` to emphasize that the matrix is shared among a group of work
items and is not private to each work item. The group scope is added
as an additional template parameter. `Group` template parameter must
be `sycl::sub_group`. In this case, a matrix is declared as follows:

```c++
joint_matrix<sub_group, int8_t, use::a, tM, tN, layout::row_major> tA;
```

=== Matrix Operations and their Execution Scope
We define three new functions needed to perform the main and common
operations on matrices, namely load, store, and the actual multiply
and add operation. This set of functions can be easily extended if the
matrix hardware implements new features.

Since the matrix functions are group operations (as defined in Section
4.17.3 of the SYCL specification), the matrix API has to be accessed
by all the work-items in the group in a convergent control flow. The
`Group` template argument must be `sycl::sub_group`.

==== Load
```c++
namespace sycl::ext::oneapi::experimental::matrix {

template <typename Group, typename T, typename S,
          size_t Rows, size_t Cols,
          access::address_space Space, access::decorated IsDecorated>
  void joint_matrix_load(Group g,
    joint_matrix<Group, T, use::accumulator, Rows, Cols,
    layout::dynamic> &res,
    multi_ptr<S, Space, IsDecorated> src, size_t stride, layout Layout);

// Only available when Layout != layout::dynamic
template <typename Group, typename T, typename S,
          size_t Rows, size_t Cols,
          use Use, layout Layout,
          access::address_space Space, access::decorated IsDecorated>
  void joint_matrix_load(Group g,
    joint_matrix<Group, T, Use, Rows, Cols, Layout> &res,
    multi_ptr<S, Space, IsDecorated> src, size_t stride);

} // namespace sycl::ext::oneapi::experimental::matrix
```

`joint_matrix_load` loads data from memory to the 2d tiles/registers
of the matrix hardware.
We define two overloads of the load function depending on whether the
memory layout was declared as part of the `joint_matrix` type or not.
The first overload that takes memory layout as an argument is only
available for a `joint_matrix` type that used the default value
`layout::dynamic`.
The second overload without a memory layout must not be used with a
`joint_matrix` type that has `layout::dynamic`.

The base pointer `src` of type `S` here determines the starting address of the
matrix to be loaded from. `Layout` determines whether the data is
being read in a row (`row_major`), column major (`col_major`)
fashion. `stride` describes the number of elements between consecutive
rows for the row major layout, or between columns for the column major
layout. Note that the type `S` must be convertible to matrix elements
type `T`.

==== Store
```c++
namespace sycl::ext::oneapi::experimental::matrix {

template <typename Group, typename T, size_t Rows, size_t Cols,
          access::address_space Space, access::decorated IsDecorated>
  void joint_matrix_store(Group g,
    joint_matrix<Group, T, use::accumulator, Rows, Cols,
    layout::dynamic> &res,
    multi_ptr<T, Space, IsDecorated> dest, size_t stride, layout Layout);

} // namespace sycl::ext::oneapi::experimental::matrix
```
This function stores the data in the accumulator matrix from the 2d
tiles back to memory.

The base pointer `dest` here determines the starting address of the
matrix to be stored. `Layout` determines whether the data is being
written in a row (`row_major`), column major (`column_major`)
fashion. `stride` describes the number of elements between consecutive
rows for the row major layout, or between columns for the column major layout.


==== Multiply and Add

```c++
namespace sycl::ext::oneapi::experimental::matrix {

template <typename Group, typename Ta, typename Tb, typename Tc,
  std::size_t M, std::size_t K, std::size_t N,
            layout LayoutA, layout LayoutB>
  joint_matrix<Group, Td, use::accumulator, M, N, layout::dynamic>
  joint_matrix_mad(Group g,
    joint_matrix<Group, Ta, use::a, M, K, LayoutA> A,
    joint_matrix<Group, Tb, use::b, K, N, LayoutB> B,
    joint_matrix<Group, Tc, use::accumulator, M, N, layout::dynamic> C);

} // namespace sycl::ext::oneapi::experimental::matrix
```
The matrix multiply and add function performs the multiply operation
on the matrices `A` and `B`, accumulates the result with `C` and returns
the result.


==== Matrix Initialization: `joint_matrix_fill`
Unlike `joint_matrix_load` that assumes that all the matrices are
directly loaded from memory, `joint_matrix_fill`  makes it possible to
multiply a matrix which is not directly loaded from memory but rather
initialized directly in the register. On Intel AMX, if the
initialization constant is zero, this would map to the `_tile_zero`
intrinsic. Note that the value type `Tv` must be convertible to the
matrix elements type `T`.

```c++
namespace sycl::ext::oneapi::experimental::matrix {

template <typename Group, typename T, size_t Rows, size_t Cols,
          use Use, layout Layout, typename Tv>
  void joint_matrix_fill(Group g, joint_matrix<Group, T, Use,
                         Rows, Cols, Layout> &m, Tv v);

} // namespace sycl::ext::oneapi::experimental::matrix
```

==== Element-Wise Operations
Besides matrix multiply and add, this extension aims to make it
possible to perform piece-wise operations on matrices in a SPMD
manner. `joint_matrix_apply` function performs an element-wise
operation where the same operation is performed on every element of
the joint matrix, such that the operation can be performed without knowledge
of the position of the element within the matrix. Activation functions
or adding a constant value to every element of the matrix are two
examples of this usage. When the operation depends on the element
index of the matrix, an Intel-specific extension is available as part
of the * link:sycl_ext_intel_matrix.asciidoc[sycl_ext_intel_matrix]

Besides the `Group` and the `joint_matrix` arguments,
`joint_matrix_apply` takes a C++ Callable object which is invoked once
for each element of the matrix. This callable object must be invocable
with a single parameter of type `T&`. Commonly, applications pass a
lambda expression.

```c++
namespace sycl::ext::oneapi::experimental::matrix {

template<typename Group, typename T, use Use, size_t Rows, size_t Cols,
  layout Layout, typename F>
  void joint_matrix_apply(Group g, joint_matrix<Group, T, Use, Rows, Cols,
  Layout>C, F&& func);

} // namespace sycl::ext::oneapi::experimental::matrix
```

In the following example, every element of the matrix `C` is
multiplied by `alpha`. Then, an activation function, `relu` in this
example, is applied on each of the elements of `C`.

```c++
joint_matrix_apply(sg, C, [=](T &x) {
    x *= alpha;
    relu(x);
});
```
IMPORTANT: `joint_matrix_apply` is not implemented yet.

=== Support for `tf32` Floating Point Type
Besides C++ `half`, `float`, `double` types, and `sycl::bfloat16` types, joint
matrix implementations may support other low-precision floating-point types
such as `tf32`. `tf32` type has a 19 bit format with one sign bit, 8
exponent bits offering the same range as `fp32`,  and 10 mantissa bits
offering same precision as  half type. The usage of `tf32` type is
restricted to `joint_matrix` using:
`sycl::ext::oneapi::experimental::matrix::precision::tf32`.

Joint matrix type `tf32` is defined as an empty class with no member functions.
```c++
namespace sycl::ext::oneapi::experimental::matrix::precision {

class tf32;

} // namespace sycl::ext::oneapi::experimental::matrix::precision
```
In this case, a `tf32` joint matrix type is declared by using the
`precision::tf32` type for the `T` template parameter as follows:

```c++
joint_matrix<sub_group, precision::tf32, use::a, tM, tK,
             layout::row_major> tA;
```

The purpose of this support is to reduce the precision of the
`joint_matrix_mad` operation. The rest of the application uses `fp32`
type. Specifically, joint matrix load/store/fill  perform float type
memory access to/from tf32 joint matrix. Also, the return type of
element-wise accesses of a tf32 `joint_matrix` returns
float. Consequently, general arithmetic is done on `fp32` data.

Joint matrix APIs manipulate floats. No implicit rounding happens when
users load or store data to/from joint matrices. By default,
`joint_matrix_mad` works on truncated values (13 bits set to zero). If
users want joint matrix data to be actually rounded to `tf32` instead of
truncated, an explicit rounding function should be used. A new function
`round_to_tf32` is added to  perform the rounding to `tf32`.

```c++
namespace sycl::ext::oneapi::experimental::matrix {

float round_to_tf32(float elem);

} // namespace sycl::ext::oneapi::experimental::matrix
```

=== Example using int8_t type
```c++
using namespace sycl::ext::oneapi::experimental::matrix;

queue q;
range<2> G = {M/tM, N};
range<2> L = {1, SG_SIZE};
int8_t *memA = malloc_shared<int8_t>(M*K, q);
int8_t *memB = malloc_shared<int8_t>(K*N, q);
int32_t *memC = malloc_shared<int32_t>(M*N, q);
q.parallel_for(nd_range<2>(G, L), [=](nd_item<2> item)
  [[sycl::reqd_sub_group_size(SG_SIZE)]] {
   const auto global_idx = item.get_global_id(0);
   const auto global_idy = item.get_global_id(1);
   const auto sg_startx = global_idx - item.get_local_id(0);
   const auto sg_starty = global_idy - item.get_local_id(1);
   sub_group sg = item.get_sub_group();
   joint_matrix<sub_group, int8_t, use::a, tM, tK, layout::row_major> tA;
   joint_matrix<sub_group, int8_t, use::b, tK, tN, layout::row_major> tB;
   joint_matrix<sub_group, int32_t, use::accumulator, tM, tN> tC;
   joint_matrix_fill(sg, tC, 0);
   for (int k = 0; k < K; k += tK) {
     joint_matrix_load(sg, tA,
          multi_ptr<int8_t, sycl::access::address_space::global_space>(memA) +
          sg_startx * tM * K + k, K);
     joint_matrix_load(sg, tB,
          multi_ptr<int8_t, sycl::access::address_space::global_space>(memB) +
          k * N + sg_starty/SG_SIZE*tN, N);
     tC = joint_matrix_mad(sg, tA, tB, tC);
   }
   joint_matrix_apply(sg, tC, [=](int8_t x) {
    x *= alpha;
   });
   joint_matrix_store(sg, tC,
        multi_ptr<int32_t, sycl::access::address_space::global_space>(memC) +
        sg_startx * tM * N + sg_starty/SG_SIZE*tN, N, layout::row_major);
}).wait();
```

=== Query Interface
Most devices support only certain values for the `Rows` and `Cols`
template parameters and only certain types for the `T` template
parameter. Moreover, most devices support only certain combinations of
these template parameter for the A, B, and accumulator matrices (see
Appendix: Supported Combinations Per Hardware). This extension adds
two query APIs that can be used to determine the set of legal
parameters for a particular device. One form provides `constexpr`
values for these parameters, which can be used when the application
knows the specific device architecture on which it will run. The other
form uses the standard information descriptor queries for the device
object.

==== Compile-Time Query
This returns `constexpr` values to use in `joint_matrix` template
arguments but depends on an enumeration of the matrix hardware (See
`sycl::ext::oneapi::experimental::architecture`) that can be tested.
The compile-time query interface proposed here consists of two
functionalities:

- Validation: at compile time, the validation functionality informs
  the user whether a specific combination is valid or not. This takes
  place when the user specifies all template parameters.

- Default values: this provides a default shape if the user does not
  provide a specific combination. In this case, aliases to the
  `joint_matrix` type can be used, namely
  `joint_matrix_a/b/accumulator` where no additional argument is
  needed. This form happens when the user specifies all template
  parameters except the sizes of the matrices (`tiles`) M, N, and K.

The table below provides a description for each of the member
variables in `matrix_params` class and the forms in which  they are
defined.

[frame="none",options="header"]
|======================
| Member/type alias in `matrix_params` | Description
|`type_a`| type alias for the type of matrix A
|`type_b`| type alias for the type of matrix B
|`type_accumulator`| type alias for the type of matrix accumulator
|`M`|when no sizes are provided by the user, indicates the suggested
default size for M; usually this corresponds to the maximum size the
implementation supports. In validation mode, where the user does
provide sizes, this is the same value M that the user provides if M is
supported by the implementation
|`N`|when no sizes are provided by the user, indicates the suggested
default size for N; usually this corresponds to the maximum size the
implementation supports. In validation mode, where the user does
provide sizes, this is the same value N that the user provides if N is
supported by the implementation
|`K`| when no sizes are provided by the user, indicates the suggested
default size for K; usually this corresponds to the maximum size the
implementation supports. In validation mode, where the user does
provide sizes, this is the same value K that the user provides if K is
supported by the implementation
|`template <typename Group, layout Layout> using joint_matrix_a;`| type
alias for `joint_matrix` for matrix A
|`template <typename Group, layout Layout> using joint_matrix_b;`| type
alias for `joint_matrix` for matrix B
|`template <typename Group> using joint_matrix_accumulator;`| type
alias for `joint_matrix` for matrix accumulator
|======================

```c++
namespace sycl::ext::oneapi::experimental::matrix {

// This is the validation form, when all template parameters are
// specified.
template<sycl::ext::oneapi::experimental::architecture Dev, typename
Ta=void, typename Tb=void, typename Taccumulator=void, size_t sM=0,
size_t sN=0, size_t sK=0>
struct matrix_params {
  // An implementation typically uses static_assert here to trigger a
  // compilation error when the matrix types or shapes are not
  // supported by the device identified by "Dev".

  using type_a = /* implementation defined */;
  using type_b = /* implementation defined */;
  using type_accumulator = /* implementation defined */;

  static constexpr size_t M = sM;
  static constexpr size_t N = sN;
  static constexpr size_t K = sK;

  template <typename Group, layout Layout>
  using joint_matrix_a = joint_matrix<Group, Ta, use::a, sM, sK, Layout>;

  template <typename Group, layout Layout>
  using joint_matrix_b = joint_matrix<Group, Tb, use::b, sK, sN, Layout>;

  template <typename Group>
  using joint_matrix_accumulator = joint_matrix<Group, Taccumulator,
  use::accumulator, sM, sN>;
};

// This is the default values form, where the matrix dimensions are
// omitted.
template<sycl::ext::oneapi::experimental::architecture Dev, typename
Ta, typename Tb, typename Taccumulator>
struct matrix_params<Dev, Ta, Tb, Taccumulator, 0, 0, 0> {
  // An implementation typically uses static_assert here to trigger a
  compilation error when the matrix types are not supported by the
  device identified by "Dev".

  using type_a = /* implementation defined */;
  using type_b = /* implementation defined */;
  using type_accumulator = /* implementation defined */;

  static constexpr size_t M = /* implementation defined */;
  static constexpr size_t N = /* implementation defined */;
  static constexpr size_t K = /* implementation defined */;

  template <typename Group, layout Layout>
  using joint_matrix_a = joint_matrix<Group, Ta, use::a, sM, sK, Layout>;

  template <typename Group, layout Layout>
  using joint_matrix_b = joint_matrix<Group, Tb, use::b, sK, sN, Layout>;

  template <typename Group>
  using joint_matrix_accumulator = joint_matrix<Group, Taccumulator,
  use::accumulator, sM, sN>;
};

} // namespace sycl::ext::oneapi::experimental::matrix
```
===== Validation Example:
```c++
// User can provide sizes besides the types and matrix_params can assert
  if they are supported or not
// in this case, an assertion will happens as 16 is not a supported size for M
using myparams =
matrix_params<sycl::ext::oneapi::experimental::architecture::intel_gpu_pvc,
int8_t, int8_t, int, 16, 16, 32>;
size_t NDRangeM = M / myparams::M;  //Assertion would happen at this line
size_t NDRangeN = N / myparams::N;
```

===== Default Values Example:
```c++
using myparams =
matrix_params<sycl::ext::oneapi::experimental::architecture::intel_gpu_pvc,
int8_t, int8_t, int>;
// use this to construct the ranges on the host side
size_t NDRangeM = M / myparams::M;
size_t NDRangeN = N / myparams::N;
//if M, N, K do not multiply the default sizes, padding has to be done
// device code: the matrices are constructed using the default dimensions
myparams::joint_matrix_a<sub_group, layout::row_major> sub_a;
myparams::joint_matrix_b<sub_group, layout::row_major> sub_b;
myparams::joint_matrix_accumulator<sub_group> sub_c;

```
==== Runtime Query
This provides a more general query interface with information about
sizes and types that are supported by a specific matrix
implementation. This is needed to avoid padding by the user, for
tuning, and efficient code generation if used by a library.

The table below provides a description for each of the device matrix
descriptors that can be queried using `get_info` API.

[frame="none",options="header"]
|======================
| Device descriptors | Return type| Description
|`ext::oneapi::experimental::info::device::matrix::combinations` |
`std::vector<combination>`| tells the set of supported matrix sizes
and types on this device
|======================

The general query returns a vector of `combinations` of `combination`
type. Each combination includes the sizes and the types for the
matrices A, B, and accumulator. Note that for each matrix hardware,
the query returns `max_msize, max_nsize, max_ksize` or `msize, nsize,
ksize` exclusively, depending on whether the implementation supports a
continuous or discrete number of sizes. If a device support a
continuous number of sizes, the `max_*` variant is applied and only
the maximum number is returned. However, if a device supports a
discrete list of numbers so the `msize, nsize, ksize` variant is applied.

```c++
namespace sycl::ext::oneapi::experimental::matrix {

enum class matrix_type {
  bf16,
  fp16,
  tf32,
  fp32,
  fp64,
  sint8,
  sint16,
  sint32,
  sint64,
  uint8,
  uint16,
  uint32,
  uint64
};
struct combination {
  uint32_t max_msize;
  uint32_t max_nsize;
  uint32_t max_ksize;
  uint32_t msize;
  uint32_t nsize;
  uint32_t ksize;
  matrix_type atype;
  matrix_type btype;
  matrix_type accumulatortype;
};

} // namespace sycl::ext::oneapi::experimental::matrix
```

Each combination of the `combinations` vector composes the types and
sizes of A, B, accumulator matrices supported by the device
implementation. The
table below provides a description of each member of the `combination` struct.

[frame="none",options="header"]
|======================
| Member of `combination` | Description
|`max_msize`, `max_nsize`, `max_ksize`| if the matrix implementation
supports a continuous number of element sizes, each of these members
is non-zero, and the matrix implementation supports all element sizes
from 1 up to (and including) that number. By contrast, if the matrix
hardware implementation supports a discrete number of element sizes,
each of these members has the value zero
|`msize`, `nsize`, `ksize`| if the matrix implementation supports a
discrete number of element sizes, each of these members is non-zero,
and the value tells one of the supported element sizes. By contrast,
if the matrix hardware supports a continuous number of element sizes,
each of these members has the value zero
|`atype`, `btype`, `accumulatortype`| indicates the types supported in
the combination. these are of type `matrix_type` which tells the list
of types that are supported for the A, B, and accumulator matrices in
the `T` template parameter as follows: +
`bf16`: `sycl::bfloat16` +
`fp16`: `sycl::half` +
`tf32`: `sycl::ext::oneapi::experimental::matrix::precision::tf32` +
`fp32`: `float` +
`fp64`: `double` +
`sint8`: signed 8 bits signed integer +
`sint16`: `signed short` +
`sint32`: `signed int` +
`sint64`: `signed long` +
`uint8`: unsigned 8 bits integer +
`uint16`: `unsigned short` +
`uint32`: `unsigned int` +
`uint64`: `unsigned long` 
|======================

===== General Query Example:
```c++
constexpr int M = 1500; // with msize = 8 and msize = 4,
          // M can be broken up to 125 sequence of 8-sized ops and
          // remaining 500 using 125 sequence of 4-sized ops
auto combinations = device.get_info<info::device::matrix::combinations>();

int {msize, nsize, ksize} = break_dimension(combinations, M);
int msize_remainder = break_dimension_remainder(combinations, M);
// device code:

//joint_matrix<sub_group, int8_t, use::a, msize, ksize,
// layout::row_major> sub_a;
//joint_matrix<sub_group, int8_t, use::b, ksize, nsize,
// layout::row_major> sub_b;
//joint_matrix<sub_group, int, use::accumulator, msize, nsize> sub_c;
//Remainder handling
```

=== Appendix: Supported Combinations Per Hardware

The table below provides a list of the combinations that
`joint_matrix` implementations support on each of Intel AMX and Intel
XMX hardware. Note that these can be returned in a parametrized way
using the `matrix_params` query class.

==== Intel AMX Supported Combinations

[frame="none",options="header"]
|======================
| A type | B type | Accumulator type | M | N | K
| `matrix_type::(u)int8`  | `matrix_type::(u)int8` |
`matrix_type::sint32`  |  +<=+ 16 |  +<=+ 16 |  +<=+ 64
|  `matrix_type::bf16`       |  `matrix_type::bf16`   |
`matrix_type::fp32`   |  +<=+ 16 |  +<=+ 16   |  +<=+ 32
|======================

==== Intel XMX Supported Combinations

[frame="none",options="header"]
|======================
| A type | B type | Accumulator type | M | N | K
| `matrix_type::(u)int8`  | `matrix_type::(u)int8` |
`matrix_type::int32`  |  +<=+ 8 |  16 |  32
|  `matrix_type::fp16`       |  `matrix_type::fp16`   |
`matrix_type::fp32`   |  +<=+ 8 |  16   |  16
|  `matrix_type::bf16`       |  `matrix_type::bf16`   |
`matrix_type::fp32`   |  +<=+ 8 |  16   |  16
|======================


=== Revision History

[frame="none",options="header"]
|======================
|Rev |Date       |Author     |Changes
|1   |2021-04-13 |Dounia Khaldi |Initial public working draft.
|2   |2021-10-05 |Dounia Khaldi |JIT implementation on both Intel AMX and DPAS
|3   |2022-05-16 |Dounia Khaldi |Add matrix fill and piece-wise
operations support
|4   |2022-08-25 |Dounia Khaldi |Update the matrix spec by adding the
new matrix use parameter and remove reference to the AOT AMX initial
implementation 
|5   |2022-11-07 |Dounia Khaldi |Update the matrix spec by making it
portable across Intel AMX, Intel XMX and Nvidia Tensor Cores, and move
the Intel-specifics to a separate extension document.
|6   |2023-01-09 |Dounia Khaldi |Add `joint_matrix_apply` API, tf32
type, runtime query, and supported combinations appendix.
|======================
